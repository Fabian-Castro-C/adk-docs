# Agente LLM

<div class="language-support-tag">
  <span class="lst-supported">Supported in ADK</span>
  <span class="lst-python">Python v0.1.0</span>
  <span class="lst-typescript">Typescript v0.2.0</span>
  <span class="lst-go">Go v0.1.0</span>
  <span class="lst-java">Java v0.1.0</span>
</div>

El `LlmAgent` (a menudo abreviado simplemente como `Agent`) es un componente central en ADK,
actuando como la parte "pensante" de tu aplicaci칩n. Aprovecha el poder de un
Modelo de Lenguaje Grande (LLM) para razonar, comprender lenguaje natural, tomar
decisiones, generar respuestas e interactuar con herramientas.

A diferencia de los [Agentes de Flujo de Trabajo](workflow-agents/index.md) deterministas que siguen
rutas de ejecuci칩n predefinidas, el comportamiento del `LlmAgent` es no determinista. Utiliza
el LLM para interpretar instrucciones y contexto, decidiendo din치micamente c칩mo
proceder, qu칠 herramientas usar (si las hay), o si transferir el control a otro
agente.

Construir un `LlmAgent` efectivo implica definir su identidad, guiar claramente
su comportamiento a trav칠s de instrucciones, y equiparlo con las herramientas y
capacidades necesarias.

## Definiendo la Identidad y Prop칩sito del Agente

Primero, necesitas establecer qu칠 *es* el agente y para qu칠 *sirve*.

* **`name` (Requerido):** Cada agente necesita un identificador de cadena 칰nico. Este
  `name` es crucial para operaciones internas, especialmente en sistemas multi-agente
  donde los agentes necesitan referirse o delegar tareas entre s칤. Elige un
  nombre descriptivo que refleje la funci칩n del agente (por ejemplo,
  `customer_support_router`, `billing_inquiry_agent`). Evita nombres reservados como
  `user`.

* **`description` (Opcional, Recomendado para Multi-Agente):** Proporciona un resumen
  conciso de las capacidades del agente. Esta descripci칩n es utilizada principalmente por
  *otros* agentes LLM para determinar si deben dirigir una tarea a este agente.
  Hazla lo suficientemente espec칤fica para diferenciarlo de sus pares (por ejemplo, "Maneja
  consultas sobre estados de facturaci칩n actuales", no solo "Agente de facturaci칩n").

* **`model` (Requerido):** Especifica el LLM subyacente que impulsar치 el
  razonamiento de este agente. Este es un identificador de cadena como `"gemini-2.5-flash"`. La
  elecci칩n del modelo impacta las capacidades del agente, el costo y el rendimiento. Consulta
  la p치gina de [Modelos](/agents/models/) para opciones disponibles y consideraciones.

=== "Python"

    ```python
    # Ejemplo: Definiendo la identidad b치sica
    capital_agent = LlmAgent(
        model="gemini-2.5-flash",
        name="capital_agent",
        description="Responde preguntas de usuarios sobre la ciudad capital de un pa칤s dado."
        # instruction y tools se agregar치n a continuaci칩n
    )
    ```

=== "Typescript"

    ```typescript
    // Ejemplo: Definiendo la identidad b치sica
    const capitalAgent = new LlmAgent({
        model: 'gemini-2.5-flash',
        name: 'capital_agent',
        description: 'Responde preguntas de usuarios sobre la ciudad capital de un pa칤s dado.',
        // instruction y tools se agregar치n a continuaci칩n
    });
    ```

=== "Go"

    ```go
    --8<-- "examples/go/snippets/agents/llm-agents/snippets/main.go:identity"
    ```

=== "Java"

    ```java
    // Ejemplo: Definiendo la identidad b치sica
    LlmAgent capitalAgent =
        LlmAgent.builder()
            .model("gemini-2.5-flash")
            .name("capital_agent")
            .description("Responde preguntas de usuarios sobre la ciudad capital de un pa칤s dado.")
            // instruction y tools se agregar치n a continuaci칩n
            .build();
    ```

## Guiando al Agente: Instrucciones (`instruction`)

El par치metro `instruction` es probablemente el m치s cr칤tico para moldear el
comportamiento de un `LlmAgent`. Es una cadena (o una funci칩n que devuelve una cadena) que
le dice al agente:

* Su tarea u objetivo principal.
* Su personalidad o persona (por ejemplo, "Eres un asistente 칰til", "Eres un pirata ingenioso").
* Restricciones en su comportamiento (por ejemplo, "Solo responde preguntas sobre X", "Nunca reveles Y").
* C칩mo y cu치ndo usar sus `tools`. Debes explicar el prop칩sito de cada herramienta y las circunstancias bajo las cuales debe ser llamada, complementando cualquier descripci칩n dentro de la herramienta misma.
* El formato deseado para su salida (por ejemplo, "Responde en JSON", "Proporciona una lista con vi침etas").

**Consejos para Instrucciones Efectivas:**

* **S칠 Claro y Espec칤fico:** Evita la ambig칲edad. Declara claramente las acciones y resultados deseados.
* **Usa Markdown:** Mejora la legibilidad para instrucciones complejas usando encabezados, listas, etc.
* **Proporciona Ejemplos (Few-Shot):** Para tareas complejas o formatos de salida espec칤ficos, incluye ejemplos directamente en la instrucci칩n.
* **Gu칤a el Uso de Herramientas:** No solo listes herramientas; explica *cu치ndo* y *por qu칠* el agente debe usarlas.

**Estado:**

* La instrucci칩n es una plantilla de cadena, puedes usar la sintaxis `{var}` para insertar valores din치micos en la instrucci칩n.
* `{var}` se usa para insertar el valor de la variable de estado llamada var.
* `{artifact.var}` se usa para insertar el contenido de texto del artefacto llamado var.
* Si la variable de estado o artefacto no existe, el agente generar치 un error. Si quieres ignorar el error, puedes agregar un `?` al nombre de la variable como en `{var?}`.

=== "Python"

    ```python
    # Ejemplo: Agregando instrucciones
    capital_agent = LlmAgent(
        model="gemini-2.5-flash",
        name="capital_agent",
        description="Responde preguntas de usuarios sobre la ciudad capital de un pa칤s dado.",
        instruction="""Eres un agente que proporciona la ciudad capital de un pa칤s.
    Cuando un usuario pregunte por la capital de un pa칤s:
    1. Identifica el nombre del pa칤s de la consulta del usuario.
    2. Usa la herramienta `get_capital_city` para encontrar la capital.
    3. Responde claramente al usuario, indicando la ciudad capital.
    Ejemplo de Consulta: "쮺u치l es la capital de {country}?"
    Ejemplo de Respuesta: "La capital de Francia es Par칤s."
    """,
        # tools se agregar치n a continuaci칩n
    )
    ```

=== "Typescript"

    ```typescript
    // Ejemplo: Agregando instrucciones
    const capitalAgent = new LlmAgent({
        model: 'gemini-2.5-flash',
        name: 'capital_agent',
        description: 'Responde preguntas de usuarios sobre la ciudad capital de un pa칤s dado.',
        instruction: `Eres un agente que proporciona la ciudad capital de un pa칤s.
            Cuando un usuario pregunte por la capital de un pa칤s:
            1. Identifica el nombre del pa칤s de la consulta del usuario.
            2. Usa la herramienta \`getCapitalCity\` para encontrar la capital.
            3. Responde claramente al usuario, indicando la ciudad capital.
            Ejemplo de Consulta: "쮺u치l es la capital de {country}?"
            Ejemplo de Respuesta: "La capital de Francia es Par칤s."
            `,
        // tools se agregar치n a continuaci칩n
    });
    ```

=== "Go"

    ```go
    --8<-- "examples/go/snippets/agents/llm-agents/snippets/main.go:instruction"
    ```

=== "Java"

    ```java
    // Ejemplo: Agregando instrucciones
    LlmAgent capitalAgent =
        LlmAgent.builder()
            .model("gemini-2.5-flash")
            .name("capital_agent")
            .description("Responde preguntas de usuarios sobre la ciudad capital de un pa칤s dado.")
            .instruction(
                """
                Eres un agente que proporciona la ciudad capital de un pa칤s.
                Cuando un usuario pregunte por la capital de un pa칤s:
                1. Identifica el nombre del pa칤s de la consulta del usuario.
                2. Usa la herramienta `get_capital_city` para encontrar la capital.
                3. Responde claramente al usuario, indicando la ciudad capital.
                Ejemplo de Consulta: "쮺u치l es la capital de {country}?"
                Ejemplo de Respuesta: "La capital de Francia es Par칤s."
                """)
            // tools se agregar치n a continuaci칩n
            .build();
    ```

*(Nota: Para instrucciones que se aplican a *todos* los agentes en un sistema, considera usar
`global_instruction` en el agente ra칤z, detallado m치s adelante en la
secci칩n [Multi-Agentes](multi-agents.md).)*

## Equipando al Agente: Herramientas (`tools`)

Las herramientas le dan a tu `LlmAgent` capacidades m치s all치 del conocimiento integrado del LLM o
razonamiento. Permiten al agente interactuar con el mundo exterior, realizar
c치lculos, obtener datos en tiempo real o ejecutar acciones espec칤ficas.

* **`tools` (Opcional):** Proporciona una lista de herramientas que el agente puede usar. Cada elemento en la lista puede ser:
    * Una funci칩n o m칠todo nativo (envuelto como un `FunctionTool`). Python ADK autom치ticamente envuelve la funci칩n nativa en un `FunctionTool` mientras que, debes envolver expl칤citamente tus m칠todos Java usando `FunctionTool.create(...)`
    * Una instancia de una clase que hereda de `BaseTool`.
    * Una instancia de otro agente (`AgentTool`, habilitando delegaci칩n agente-a-agente - ver [Multi-Agentes](multi-agents.md)).

El LLM usa los nombres de funci칩n/herramienta, descripciones (de docstrings o el
campo `description`), y esquemas de par치metros para decidir qu칠 herramienta llamar bas치ndose
en la conversaci칩n y sus instrucciones.

=== "Python"

    ```python
    # Define una funci칩n de herramienta
    def get_capital_city(country: str) -> str:
      """Recupera la ciudad capital para un pa칤s dado."""
      # Reemplaza con l칩gica real (ej., llamada API, b칰squeda en base de datos)
      capitals = {"france": "Paris", "japan": "Tokyo", "canada": "Ottawa"}
      return capitals.get(country.lower(), f"Lo siento, no conozco la capital de {country}.")

    # Agrega la herramienta al agente
    capital_agent = LlmAgent(
        model="gemini-2.5-flash",
        name="capital_agent",
        description="Responde preguntas de usuarios sobre la ciudad capital de un pa칤s dado.",
        instruction="""Eres un agente que proporciona la ciudad capital de un pa칤s... (texto de instrucci칩n anterior)""",
        tools=[get_capital_city] # Proporciona la funci칩n directamente
    )
    ```

=== "Typescript"

    ```typescript
    import {z} from 'zod';
    import { LlmAgent, FunctionTool } from '@google/adk';

    // Define el esquema para los par치metros de entrada de la herramienta
    const getCapitalCityParamsSchema = z.object({
        country: z.string().describe('El pa칤s para el cual obtener la capital.'),
    });

    // Define la funci칩n de herramienta en s칤
    async function getCapitalCity(params: z.infer<typeof getCapitalCityParamsSchema>): Promise<{ capitalCity: string }> {
    const capitals: Record<string, string> = {
        'france': 'Paris',
        'japan': 'Tokyo',
        'canada': 'Ottawa',
    };
    const result = capitals[params.country.toLowerCase()] ??
        `Lo siento, no conozco la capital de ${params.country}.`;
    return {capitalCity: result}; // Las herramientas deben devolver un objeto
    }

    // Crea una instancia del FunctionTool
    const getCapitalCityTool = new FunctionTool({
        name: 'getCapitalCity',
        description: 'Recupera la ciudad capital para un pa칤s dado.',
        parameters: getCapitalCityParamsSchema,
        execute: getCapitalCity,
    });

    // Agrega la herramienta al agente
    const capitalAgent = new LlmAgent({
        model: 'gemini-2.5-flash',
        name: 'capitalAgent',
        description: 'Responde preguntas de usuarios sobre la ciudad capital de un pa칤s dado.',
        instruction: 'Eres un agente que proporciona la ciudad capital de un pa칤s...', // Nota: la instrucci칩n completa se omite por brevedad
        tools: [getCapitalCityTool], // Proporciona la instancia de FunctionTool en un array
    });
    ```

=== "Go"

    ```go
    --8<-- "examples/go/snippets/agents/llm-agents/snippets/main.go:tool_example"
    ```

=== "Java"

    ```java

    // Define una funci칩n de herramienta
    // Recupera la ciudad capital de un pa칤s dado.
    public static Map<String, Object> getCapitalCity(
            @Schema(name = "country", description = "El pa칤s para el cual obtener la capital")
            String country) {
      // Reemplaza con l칩gica real (ej., llamada API, b칰squeda en base de datos)
      Map<String, String> countryCapitals = new HashMap<>();
      countryCapitals.put("canada", "Ottawa");
      countryCapitals.put("france", "Paris");
      countryCapitals.put("japan", "Tokyo");

      String result =
              countryCapitals.getOrDefault(
                      country.toLowerCase(), "Lo siento, no pude encontrar la capital de " + country + ".");
      return Map.of("result", result); // Las herramientas deben devolver un Map
    }

    // Agrega la herramienta al agente
    FunctionTool capitalTool = FunctionTool.create(experiment.getClass(), "getCapitalCity");
    LlmAgent capitalAgent =
        LlmAgent.builder()
            .model("gemini-2.5-flash")
            .name("capital_agent")
            .description("Responde preguntas de usuarios sobre la ciudad capital de un pa칤s dado.")
            .instruction("Eres un agente que proporciona la ciudad capital de un pa칤s... (texto de instrucci칩n anterior)")
            .tools(capitalTool) // Proporciona la funci칩n envuelta como un FunctionTool
            .build();
    ```

Aprende m치s sobre Herramientas en la secci칩n [Herramientas](../tools/index.md).

## Configuraci칩n y Control Avanzados

M치s all치 de los par치metros centrales, `LlmAgent` ofrece varias opciones para un control m치s fino:

### Ajustando la Generaci칩n del LLM (`generate_content_config`)

Puedes ajustar c칩mo el LLM subyacente genera respuestas usando `generate_content_config`.

* **`generate_content_config` (Opcional):** Pasa una instancia de [`google.genai.types.GenerateContentConfig`](https://googleapis.github.io/python-genai/genai.html#genai.types.GenerateContentConfig) para controlar par치metros como `temperature` (aleatoriedad), `max_output_tokens` (longitud de respuesta), `top_p`, `top_k`, y configuraciones de seguridad.

=== "Python"

    ```python
    from google.genai import types

    agent = LlmAgent(
        # ... otros par치metros
        generate_content_config=types.GenerateContentConfig(
            temperature=0.2, # Salida m치s determinista
            max_output_tokens=250,
            safety_settings=[
                types.SafetySetting(
                    category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
                    threshold=types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
                )
            ]
        )
    )
    ```

=== "Typescript"

    ```typescript
    import { GenerateContentConfig } from '@google/genai';

    const generateContentConfig: GenerateContentConfig = {
        temperature: 0.2, // Salida m치s determinista
        maxOutputTokens: 250,
    };

    const agent = new LlmAgent({
        // ... otros par치metros
        generateContentConfig,
    });
    ```

=== "Go"

    ```go
    import "google.golang.org/genai"

    --8<-- "examples/go/snippets/agents/llm-agents/snippets/main.go:gen_config"
    ```

=== "Java"

    ```java
    import com.google.genai.types.GenerateContentConfig;

    LlmAgent agent =
        LlmAgent.builder()
            // ... otros par치metros
            .generateContentConfig(GenerateContentConfig.builder()
                .temperature(0.2F) // Salida m치s determinista
                .maxOutputTokens(250)
                .build())
            .build();
    ```

### Estructurando Datos (`input_schema`, `output_schema`, `output_key`)

Para escenarios que requieren intercambio de datos estructurados con un `LLM Agent`, el ADK proporciona mecanismos para definir formatos de entrada esperados y salida deseados usando definiciones de esquema.

* **`input_schema` (Opcional):** Define un esquema que representa la estructura de entrada esperada. Si se establece, el contenido del mensaje del usuario pasado a este agente *debe* ser una cadena JSON que cumpla con este esquema. Tus instrucciones deben guiar al usuario o agente precedente en consecuencia.

* **`output_schema` (Opcional):** Define un esquema que representa la estructura de salida deseada. Si se establece, la respuesta final del agente *debe* ser una cadena JSON que cumpla con este esquema.

* **`output_key` (Opcional):** Proporciona una clave de cadena. Si se establece, el contenido de texto de la respuesta *final* del agente se guardar치 autom치ticamente en el diccionario de estado de la sesi칩n bajo esta clave. Esto es 칰til para pasar resultados entre agentes o pasos en un flujo de trabajo.
    * En Python, esto podr칤a verse como: `session.state[output_key] = agent_response_text`
    * En Java: `session.state().put(outputKey, agentResponseText)`
    * En Golang, dentro de un manejador de callback: `ctx.State().Set(output_key, agentResponseText)`

=== "Python"

    El esquema de entrada y salida es t칤picamente un `Pydantic` BaseModel.

    ```python
    from pydantic import BaseModel, Field

    class CapitalOutput(BaseModel):
        capital: str = Field(description="La capital del pa칤s.")

    structured_capital_agent = LlmAgent(
        # ... name, model, description
        instruction="""Eres un Agente de Informaci칩n de Capitales. Dado un pa칤s, responde SOLO con un objeto JSON que contenga la capital. Formato: {"capital": "nombre_capital"}""",
        output_schema=CapitalOutput, # Forzar salida JSON
        output_key="found_capital"  # Almacenar resultado en state['found_capital']
        # No se puede usar tools=[get_capital_city] efectivamente aqu칤
    )
    ```

=== "Typescript"

    ```typescript
    import {z} from 'zod';
    import { Schema, Type } from '@google/genai';

    // Define el esquema para la salida
    const CapitalOutputSchema: Schema = {
        type: Type.OBJECT,
        properties: {
            capital: {
                type: Type.STRING,
                description: 'La capital del pa칤s.',
            },
        },
        required: ['capital'],
    };

    // Crea la instancia de LlmAgent
    const structuredCapitalAgent = new LlmAgent({
        // ... name, model, description
        instruction: `Eres un Agente de Informaci칩n de Capitales. Dado un pa칤s, responde SOLO con un objeto JSON que contenga la capital. Formato: {"capital": "nombre_capital"}`,
        outputSchema: CapitalOutputSchema, // Forzar salida JSON
        outputKey: 'found_capital', // Almacenar resultado en state['found_capital']
        // No se pueden usar tools efectivamente aqu칤
    });
    ```

=== "Go"

    El esquema de entrada y salida es un objeto `google.genai.types.Schema`.

    ```go
    --8<-- "examples/go/snippets/agents/llm-agents/snippets/main.go:schema_example"
    ```

=== "Java"

     El esquema de entrada y salida es un objeto `google.genai.types.Schema`.

    ```java
    private static final Schema CAPITAL_OUTPUT =
        Schema.builder()
            .type("OBJECT")
            .description("Esquema para informaci칩n de ciudad capital.")
            .properties(
                Map.of(
                    "capital",
                    Schema.builder()
                        .type("STRING")
                        .description("La ciudad capital del pa칤s.")
                        .build()))
            .build();

    LlmAgent structuredCapitalAgent =
        LlmAgent.builder()
            // ... name, model, description
            .instruction(
                    "Eres un Agente de Informaci칩n de Capitales. Dado un pa칤s, responde SOLO con un objeto JSON que contenga la capital. Formato: {\"capital\": \"nombre_capital\"}")
            .outputSchema(capitalOutput) // Forzar salida JSON
            .outputKey("found_capital") // Almacenar resultado en state.get("found_capital")
            // No se puede usar tools(getCapitalCity) efectivamente aqu칤
            .build();
    ```

### Gestionando Contexto (`include_contents`)

Controla si el agente recibe el historial de conversaci칩n anterior.

* **`include_contents` (Opcional, Por defecto: `'default'`):** Determina si los `contents` (historial) se env칤an al LLM.
    * `'default'`: El agente recibe el historial de conversaci칩n relevante.
    * `'none'`: El agente no recibe `contents` anteriores. Opera bas치ndose 칰nicamente en su instrucci칩n actual y cualquier entrada proporcionada en el turno *actual* (칰til para tareas sin estado o para aplicar contextos espec칤ficos).

=== "Python"

    ```python
    stateless_agent = LlmAgent(
        # ... otros par치metros
        include_contents='none'
    )
    ```

=== "Typescript"

    ```typescript
    const statelessAgent = new LlmAgent({
        // ... otros par치metros
        includeContents: 'none',
    });
    ```

=== "Go"

    ```go
    import "google.golang.org/adk/agent/llmagent"

    --8<-- "examples/go/snippets/agents/llm-agents/snippets/main.go:include_contents"
    ```

=== "Java"

    ```java
    import com.google.adk.agents.LlmAgent.IncludeContents;

    LlmAgent statelessAgent =
        LlmAgent.builder()
            // ... otros par치metros
            .includeContents(IncludeContents.NONE)
            .build();
    ```

### Planificador

<div class="language-support-tag" title="">
   <span class="lst-supported">Supported in ADK</span><span class="lst-python">Python v0.1.0</span>
</div>

**`planner` (Opcional):** Asigna una instancia de `BasePlanner` para habilitar razonamiento y planificaci칩n de m칰ltiples pasos antes de la ejecuci칩n. Hay dos planificadores principales:

* **`BuiltInPlanner`:** Aprovecha las capacidades de planificaci칩n integradas del modelo (por ejemplo, la funci칩n de pensamiento de Gemini). Ver [Gemini Thinking](https://ai.google.dev/gemini-api/docs/thinking) para detalles y ejemplos.

    Aqu칤, el par치metro `thinking_budget` gu칤a al modelo sobre el n칰mero de tokens de pensamiento a usar al generar una respuesta. El par치metro `include_thoughts` controla si el modelo debe incluir sus pensamientos crudos y proceso de razonamiento interno en la respuesta.

    ```python
    from google.adk import Agent
    from google.adk.planners import BuiltInPlanner
    from google.genai import types

    my_agent = Agent(
        model="gemini-2.5-flash",
        planner=BuiltInPlanner(
            thinking_config=types.ThinkingConfig(
                include_thoughts=True,
                thinking_budget=1024,
            )
        ),
        # ... tus herramientas aqu칤
    )
    ```

* **`PlanReActPlanner`:** Este planificador instruye al modelo para seguir una estructura espec칤fica en su salida: primero crear un plan, luego ejecutar acciones (como llamar herramientas), y proporcionar razonamiento para sus pasos. *Es particularmente 칰til para modelos que no tienen una funci칩n de "pensamiento" integrada*.

    ```python
    from google.adk import Agent
    from google.adk.planners import PlanReActPlanner

    my_agent = Agent(
        model="gemini-2.5-flash",
        planner=PlanReActPlanner(),
        # ... tus herramientas aqu칤
    )
    ```

    La respuesta del agente seguir치 un formato estructurado:

    ```
    [user]: ai news
    [google_search_agent]: /*PLANNING*/
    1. Realizar una b칰squeda en Google de "칰ltimas noticias de IA" para obtener actualizaciones actuales y titulares relacionados con inteligencia artificial.
    2. Sintetizar la informaci칩n de los resultados de b칰squeda para proporcionar un resumen de noticias recientes de IA.

    /*ACTION*/
    /*REASONING*/
    Los resultados de b칰squeda proporcionan una visi칩n general completa de noticias recientes de IA, cubriendo varios aspectos como desarrollos de empresas, avances en investigaci칩n y aplicaciones. Tengo suficiente informaci칩n para responder a la solicitud del usuario.

    /*FINAL_ANSWER*/
    Aqu칤 hay un resumen de noticias recientes de IA:
    ....
    ```

Ejemplo para usar built-in-planner:

```python
from dotenv import load_dotenv


import asyncio
import os

from google.genai import types
from google.adk.agents.llm_agent import LlmAgent
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.adk.artifacts.in_memory_artifact_service import InMemoryArtifactService # Opcional
from google.adk.planners import BasePlanner, BuiltInPlanner, PlanReActPlanner
from google.adk.models import LlmRequest

from google.genai.types import ThinkingConfig
from google.genai.types import GenerateContentConfig

import datetime
from zoneinfo import ZoneInfo

APP_NAME = "weather_app"
USER_ID = "1234"
SESSION_ID = "session1234"

def get_weather(city: str) -> dict:
    """Recupera el reporte de clima actual para una ciudad especificada.

    Args:
        city (str): El nombre de la ciudad para la cual recuperar el reporte de clima.

    Returns:
        dict: status y result o msg de error.
    """
    if city.lower() == "new york":
        return {
            "status": "success",
            "report": (
                "El clima en Nueva York es soleado con una temperatura de 25 grados"
                " Celsius (77 grados Fahrenheit)."
            ),
        }
    else:
        return {
            "status": "error",
            "error_message": f"La informaci칩n del clima para '{city}' no est치 disponible.",
        }


def get_current_time(city: str) -> dict:
    """Devuelve la hora actual en una ciudad especificada.

    Args:
        city (str): El nombre de la ciudad para la cual recuperar la hora actual.

    Returns:
        dict: status y result o msg de error.
    """

    if city.lower() == "new york":
        tz_identifier = "America/New_York"
    else:
        return {
            "status": "error",
            "error_message": (
                f"Lo siento, no tengo informaci칩n de zona horaria para {city}."
            ),
        }

    tz = ZoneInfo(tz_identifier)
    now = datetime.datetime.now(tz)
    report = (
        f'La hora actual en {city} es {now.strftime("%Y-%m-%d %H:%M:%S %Z%z")}'
    )
    return {"status": "success", "report": report}

# Paso 1: Crear un ThinkingConfig
thinking_config = ThinkingConfig(
    include_thoughts=True,   # Pedir al modelo que incluya sus pensamientos en la respuesta
    thinking_budget=256      # Limitar el 'pensamiento' a 256 tokens (ajustar seg칰n sea necesario)
)
print("ThinkingConfig:", thinking_config)

# Paso 2: Instanciar BuiltInPlanner
planner = BuiltInPlanner(
    thinking_config=thinking_config
)
print("BuiltInPlanner creado.")

# Paso 3: Envolver el planificador en un LlmAgent
agent = LlmAgent(
    model="gemini-2.5-pro-preview-03-25",  # Establece el nombre de tu modelo
    name="weather_and_time_agent",
    instruction="Eres un agente que devuelve hora y clima",
    planner=planner,
    tools=[get_weather, get_current_time]
)

# Session y Runner
session_service = InMemorySessionService()
session = session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)
runner = Runner(agent=agent, app_name=APP_NAME, session_service=session_service)

# Interacci칩n con el Agente
def call_agent(query):
    content = types.Content(role='user', parts=[types.Part(text=query)])
    events = runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content)

    for event in events:
        print(f"\nDEBUG EVENT: {event}\n")
        if event.is_final_response() and event.content:
            final_answer = event.content.parts[0].text.strip()
            print("\n游릭 FINAL ANSWER\n", final_answer, "\n")

call_agent("Si est치 lloviendo en Nueva York ahora mismo, 쯖u치l es la temperatura actual?")

```

### Ejecuci칩n de C칩digo

<div class="language-support-tag">
   <span class="lst-supported">Supported in ADK</span><span class="lst-python">Python v0.1.0</span><span class="lst-java">Java v0.1.0</span>
</div>

- **`code_executor` (Opcional):** Proporciona una instancia de `BaseCodeExecutor` para permitir
  al agente ejecutar bloques de c칩digo encontrados en la respuesta del LLM. Para m치s
  informaci칩n, ver [Ejecuci칩n de C칩digo con Gemini API](/tools/gemini-api/code-execution/).

=== "Python"

    ```python
    --8<-- "examples/python/snippets/tools/built-in-tools/code_execution.py"
    ```

=== "Java"

    ```java
    --8<-- "examples/java/snippets/src/main/java/tools/CodeExecutionAgentApp.java:full_code"
    ```

## Juntando Todo: Ejemplo

??? "Code"
    Aqu칤 est치 el `capital_agent` b치sico completo:

    === "Python"

        ```python
        --8<-- "examples/python/snippets/agents/llm-agent/capital_agent.py"
        ```

    === "Typescript"

        ```javascript
        --8<-- "examples/typescript/snippets/agents/llm-agent/capital_agent.ts"
        ```

    === "Go"

        ```go
        --8<-- "examples/go/snippets/agents/llm-agents/main.go:full_code"
        ```

    === "Java"

        ```java
        --8<-- "examples/java/snippets/src/main/java/agents/LlmAgentExample.java:full_code"
        ```

_(Este ejemplo demuestra los conceptos centrales. Agentes m치s complejos podr칤an incorporar esquemas, control de contexto, planificaci칩n, etc.)_

## Conceptos Relacionados (Temas Diferidos)

Mientras esta p치gina cubre la configuraci칩n central de `LlmAgent`, varios conceptos relacionados proporcionan control m치s avanzado y se detallan en otros lugares:

* **Callbacks:** Interceptar puntos de ejecuci칩n (antes/despu칠s de llamadas al modelo, antes/despu칠s de llamadas a herramientas) usando `before_model_callback`, `after_model_callback`, etc. Ver [Callbacks](../callbacks/types-of-callbacks.md).
* **Control Multi-Agente:** Estrategias avanzadas para interacci칩n de agentes, incluyendo planificaci칩n (`planner`), control de transferencia de agentes (`disallow_transfer_to_parent`, `disallow_transfer_to_peers`), e instrucciones de todo el sistema (`global_instruction`). Ver [Multi-Agentes](multi-agents.md).